# Procesamiento de Contenido Multi-Modal con Memoria: Llevando Strands Agent al Siguiente Nivel

*Parte 2: Agregando Memoria Persistente con FAISS*

En nuestro [art√≠culo anterior](https://dev.to/aws/multi-modal-content-processing-with-strands-agent-and-just-a-few-lines-of-code-4hn4), exploramos c√≥mo construir un agente de IA multi-modal capaz de procesar im√°genes, documentos y videos usando el framework Strands Agent. Hoy, vamos un paso m√°s all√° agregando **capacidades de memoria persistente** usando FAISS (Facebook AI Similarity Search) para crear un agente que puede recordar y recuperar informaci√≥n a trav√©s de sesiones.

## üß† Por Qu√© Importa la Memoria

Imagina tener un asistente de IA que no solo procesa tu contenido, sino que tambi√©n recuerda lo que le has mostrado antes. Esto abre casos de uso poderosos:

- **Conversaciones contextuales**: "¬øRecuerdas ese diagrama de arquitectura que te mostr√© ayer? ¬øC√≥mo se relaciona con este nuevo documento?"
- **Aprendizaje progresivo**: Construir conocimiento a lo largo del tiempo a partir de m√∫ltiples interacciones
- **Respuestas personalizadas**: Adaptar respuestas basadas en tus preferencias y contenido previo
- **Continuidad entre sesiones**: Mantener contexto incluso despu√©s de reiniciar tu aplicaci√≥n

## üöÄ Lo Que Estamos Construyendo

Mejoraremos nuestro agente multi-modal con:

1. **Almacenamiento de memoria con FAISS** usando la herramienta `mem0_memory`
2. **Almacenamiento persistente de informaci√≥n** a trav√©s de sesiones
3. **Recuperaci√≥n inteligente** de memorias relevantes basada en contexto
4. **Operaciones de gesti√≥n de memoria** (almacenar, recuperar, listar)

## üõ†Ô∏è Configurando el Agente Mejorado

Comencemos configurando nuestro agente con capacidades de memoria:

```python
import boto3
from strands.models import BedrockModel
from strands import Agent
from strands_tools import image_reader, file_read, mem0_memory, use_llm
from video_reader import video_reader

# Prompt del sistema mejorado con instrucciones de memoria
MULTIMODAL_SYSTEM_PROMPT = """ Eres un asistente √∫til que puede procesar documentos, im√°genes y videos. 
Analiza su contenido y proporciona informaci√≥n relevante. Tienes capacidades de memoria y puedes recordar interacciones previas.

Puedes:
1. Para formatos PNG, JPEG/JPG, GIF o WebP usa image_reader para procesar el archivo
2. Para formatos PDF, csv, docx, xls o xlsx usa file_read para procesar el archivo  
3. Para formatos MP4, MOV, AVI, MKV, WebM usa video_reader para procesar el archivo
4. Simplemente entregar la respuesta

Capacidades de memoria:
- Almacenar nueva informaci√≥n usando la herramienta mem0_memory (action="store")
- Recuperar memorias relevantes (action="retrieve")
- Listar todas las memorias (action="list")
- Proporcionar respuestas personalizadas

Reglas clave:
- Siempre incluir user_id={USER_ID} en las llamadas a herramientas
- Ser conversacional y natural en las respuestas
- Formatear la salida claramente
- Reconocer informaci√≥n almacenada
- Referenciar interacciones pasadas relevantes cuando sea apropiado
"""

# Configurar AWS Bedrock
session = boto3.Session(region_name='us-west-2')
bedrock_model = BedrockModel(
    model_id="us.anthropic.claude-3-7-sonnet-20250219-v1:0",
    boto_session=session,
    streaming=False
)

# Crear agente mejorado con capacidades de memoria
multimodal_agent = Agent(
    system_prompt=MULTIMODAL_SYSTEM_PROMPT,
    tools=[image_reader, file_read, video_reader, mem0_memory, use_llm],
    model=bedrock_model,
)
```

## üíæ Operaciones de Memoria en Acci√≥n

### 1. Almacenando Contexto Inicial del Usuario

Primero, almacenemos informaci√≥n b√°sica sobre nuestro usuario:

```python
USER_ID = "eli_abc"  # Generar un ID √∫nico de usuario
content = """Hola, mi nombre es Elizabeth, pero me dicen Eli. Soy developer advocate en AWS, 
y quiero entender qu√© hay en im√°genes, videos y documentos para mejorar mi trabajo diario."""

# Almacenar contexto del usuario en memoria
multimodal_agent.tool.mem0_memory(action="store", content=content, user_id=USER_ID)
```

### 2. An√°lisis de Imagen con Almacenamiento en Memoria

Ahora analicemos una imagen y almacenemos autom√°ticamente los resultados:

```python
print("=== üì∏ AN√ÅLISIS DE IMAGEN CON MEMORIA ===")
image_result = multimodal_agent(
    f"Analiza la imagen data-sample/diagram.jpg en detalle y describe todo lo que observas. "
    f"Recuerda esta informaci√≥n para m√°s tarde. USER_ID: {USER_ID}"
)
print(image_result)
```

El agente:
1. Procesar√° la imagen usando `image_reader`
2. Analizar√° el diagrama arquitect√≥nico
3. Almacenar√° autom√°ticamente el an√°lisis en memoria usando `mem0_memory`
4. Proporcionar√° una descripci√≥n detallada

### 3. An√°lisis de Video con Memoria

Procesemos un video y almacenemos su contenido:

```python
print("=== üé¨ AN√ÅLISIS DE VIDEO CON MEMORIA ===")
video_result = multimodal_agent(
    "Analiza el video data-sample/moderation-video.mp4 y describe en detalle "
    "las acciones y escenas que observas. Almacena esta informaci√≥n en tu memoria."
)
print(video_result)
```

### 4. Procesamiento de Documento con Memoria

Procesa y recuerda el contenido del documento:

```python
print("=== üìÑ AN√ÅLISIS DE DOCUMENTO CON MEMORIA ===")
doc_result = multimodal_agent(
    "Resume como json el contenido del documento data-sample/Welcome-Strands-Agents-SDK.pdf "
    "y almacena esta informaci√≥n en tu memoria."
)
print(doc_result)
```

## üîç Recuperaci√≥n y Gesti√≥n de Memoria

### Recuperando Memorias Espec√≠ficas

```python
# Recuperar memorias relacionadas con una consulta espec√≠fica
retrieved_memories = multimodal_agent.tool.mem0_memory(
    action="retrieve", 
    query="¬øQu√© servicios est√°n en la imagen?", 
    user_id=USER_ID
)
print("Memorias Recuperadas:", retrieved_memories)
```

### Listando Todas las Memorias Almacenadas

```python
# Listar todas las memorias almacenadas para el usuario
all_memories = multimodal_agent.tool.mem0_memory(
    action="list", 
    user_id=USER_ID
)
print("Todas las Memorias Almacenadas:", all_memories)
```

### Probando Recuperaci√≥n de Memoria Cross-Modal

El verdadero poder viene al probar la memoria a trav√©s de diferentes tipos de medios:

```python
print("=== üß† PRUEBA DE RECUPERACI√ìN DE MEMORIA ===")
memory_result = multimodal_agent(
    "¬øQu√© recuerdas sobre la imagen, video y documento que te mostr√© anteriormente?"
)
print(memory_result)
```

## üéØ Casos de Uso del Mundo Real

Este agente mejorado con memoria abre numerosas aplicaciones pr√°cticas:

### 1. **Asistente de Documentaci√≥n T√©cnica**
- Recordar diagramas de arquitectura, fragmentos de c√≥digo y documentaci√≥n
- Proporcionar respuestas contextuales basadas en tu historial de proyecto
- Rastrear cambios y evoluci√≥n de tus dise√±os t√©cnicos

### 2. **Pipeline de An√°lisis de Contenido**
- Procesar lotes de im√°genes, videos y documentos
- Construir una base de conocimiento de contenido analizado
- Generar reportes basados en insights acumulados

### 3. **Gesti√≥n de Conocimiento Personal**
- Almacenar y recordar informaci√≥n de varios tipos de medios
- Crear conexiones entre diferentes piezas de contenido
- Construir un asistente de IA personalizado que crezca con tus necesidades

### 4. **Procesamiento de Contenido Educativo**
- Analizar materiales educativos en diferentes formatos
- Recordar preferencias y patrones de aprendizaje de estudiantes
- Proporcionar recomendaciones de aprendizaje personalizadas

## üîß Caracter√≠sticas y Beneficios Clave

### **Memoria Persistente**
- La informaci√≥n sobrevive a reinicios de aplicaci√≥n
- B√∫squeda de similitud con FAISS para recuperaci√≥n relevante
- Almacenamiento y consulta eficiente de grandes cantidades de datos

### **Comprensi√≥n Cross-Modal**
- Conectar insights de im√°genes, videos y documentos
- Construir comprensi√≥n integral a trav√©s de tipos de medios
- Generar respuestas hol√≠sticas basadas en m√∫ltiples fuentes

### **Personalizaci√≥n**
- Almacenamiento de memoria espec√≠fico por usuario con IDs √∫nicos
- Respuestas adaptadas basadas en historial del usuario
- Aprendizaje progresivo de interacciones del usuario

### **Escalabilidad**
- Manejar grandes vol√∫menes de contenido y memorias
- B√∫squeda de similitud eficiente usando FAISS
- Optimizado para cargas de trabajo de producci√≥n

## üöÄ Comenzando

1. **Clonar el repositorio**:
   ```bash
   git clone <repository-url>
   cd notebook
   ```

2. **Instalar dependencias**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Configurar credenciales de AWS** para acceso a Bedrock

4. **Ejecutar el notebook**:
   ```bash
   jupyter notebook multi-understanding-with-memory.ipynb
   ```

## üéâ ¬øQu√© Sigue?

Con procesamiento multi-modal mejorado con memoria, puedes:

- Construir asistentes de IA m√°s sofisticados
- Crear pipelines de an√°lisis de contenido personalizados
- Desarrollar aplicaciones que aprenden y mejoran con el tiempo
- Implementar continuidad entre sesiones en tus flujos de trabajo de IA

La combinaci√≥n de las capacidades multi-modales de Strands Agent con memoria persistente crea una base poderosa para construir aplicaciones inteligentes y conscientes del contexto que pueden verdaderamente entender y recordar tu contenido.

## üìö Recursos

- [Documentaci√≥n de Strands Agent](https://github.com/awslabs/strands)
- [Parte 1: Procesamiento Multi-Modal B√°sico](https://dev.to/aws/multi-modal-content-processing-with-strands-agent-and-just-a-few-lines-of-code-4hn4)
- [Ejemplos de C√≥digo Completos](https://github.com/your-repo/multi-understanding-notebooks)
- [Documentaci√≥n de AWS Bedrock](https://docs.aws.amazon.com/bedrock/)

---

*¬øListo para construir tu propio agente de IA mejorado con memoria? ¬°Prueba el notebook completo y cu√©ntanos qu√© aplicaciones incre√≠bles creas!*

#AWS #IA #AprendizajeAutomatico #MultiModal #FAISS #StrandsAgent #Bedrock #Memoria #InteligenciaArtificial
