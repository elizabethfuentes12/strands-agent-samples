{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde193fa",
   "metadata": {},
   "source": [
    "# ðŸŽ¯ Multi-Agent Multimodal Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b730f098",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from strands.models import BedrockModel\n",
    "from strands import Agent\n",
    "from strands_tools import image_reader, file_read\n",
    "from video_reader import video_reader\n",
    "from strands.tools import tool\n",
    "\n",
    "\n",
    "# video_reader is already available as a built-in tool\n",
    "agent = Agent(tools=[image_reader, file_read, video_reader])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4559fc",
   "metadata": {},
   "source": [
    "## ðŸ¤– Agent Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba48f5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated multimodal system prompt to include video support\n",
    "MULTIMODAL_SYSTEM_PROMPT = \"\"\" You are a helpful assistant that can process documents, images, and videos. \n",
    "Analyze their contents and provide relevant information.\n",
    "\n",
    "You can:\n",
    "\n",
    "1. For PNG, JPEG/JPG, GIF, or WebP formats use image_reader to process file\n",
    "2. For PDF, csv, docx, xls or xlsx formats use file_read to process file  \n",
    "3. For MP4, MOV, AVI, MKV, WebM formats use video_reader to process file\n",
    "4. Just deliver the answer\n",
    "\n",
    "When displaying responses:\n",
    "- Format answers data in a human-readable way\n",
    "- Highlight important information\n",
    "- Handle errors appropriately\n",
    "- Convert technical terms to user-friendly language\n",
    "- Always reply in the original user language\n",
    "\n",
    "Always reply in the original user language.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# video_reader is available as built-in tool\n",
    "# video_reader is already imported above\n",
    "# load_tool(path=\"tools/video_reader.py\", name=\"video_reader\")  # This was causing errors\n",
    "\n",
    "session = boto3.Session(region_name='us-west-2')\n",
    "\n",
    "bedrock_model = BedrockModel(\n",
    "    model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "    #model_id=\"us.amazon.nova-pro-v1:0\",\n",
    "    boto_session=session,\n",
    "    streaming=False\n",
    ")\n",
    "\n",
    "# Updated multimodal agent with video support\n",
    "multimodal_agent = Agent(\n",
    "    system_prompt=MULTIMODAL_SYSTEM_PROMPT,\n",
    "    tools=[image_reader, file_read, video_reader],\n",
    "    model=bedrock_model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef6f952",
   "metadata": {},
   "source": [
    "## ðŸŽ¯ Usage Examples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994e1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Image analysis\n",
    "print(\"=== ðŸ“¸ IMAGE ANALYSIS ===\")\n",
    "image_result = multimodal_agent(\"Analyze the image data-sample/diagram.jpg in detail and describe everything you observe\")\n",
    "print(image_result)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45875c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_result.message['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bf805a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Video analysis\n",
    "print(\"=== ðŸŽ¬ VIDEO ANALYSIS ===\")\n",
    "video_result = multimodal_agent(\"Analyze the video data-sample/moderation-video.mp4 and describe in detail the actions and scenes you observe\")\n",
    "print(video_result)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec38e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_result.message['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30275dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Document analysis (if you have a PDF document)\n",
    "print(\"=== ðŸ“„ DOCUMENT ANALYSIS ===\")\n",
    "doc_result = multimodal_agent(\"Summarize as json the content of the document data-sample/Welcome-Strands-Agents-SDK.pdf\")\n",
    "print(doc_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b24ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_result.message['content'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e352333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4. Direct use of tools\n",
    "video_analysis = multimodal_agent.tool.video_reader(\n",
    "     video_path=\"data-sample/moderation-video.mp4\", \n",
    "     text_prompt=\"What are the main elements in this video?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008a60db",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3171cac0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9272f06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
